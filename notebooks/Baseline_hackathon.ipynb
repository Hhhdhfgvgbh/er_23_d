{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d11335e",
      "metadata": {
        "id": "2d11335e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!pip3 install pytorch-lifestream"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9iaxpIoS1AgF",
      "metadata": {
        "id": "9iaxpIoS1AgF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from functools import partial\n",
        "import pytorch_lightning as pl\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from ptls.data_load.datasets import MemoryMapDataset\n",
        "from ptls.data_load.iterable_processing.iterable_seq_len_limit import ISeqLenLimit\n",
        "from ptls.data_load.iterable_processing.to_torch_tensor import ToTorch\n",
        "from ptls.data_load.iterable_processing.feature_filter import FeatureFilter\n",
        "from ptls.nn import TrxEncoder, RnnSeqEncoder\n",
        "from ptls.frames.coles import CoLESModule\n",
        "from ptls.data_load.iterable_processing import SeqLenFilter\n",
        "from ptls.frames.coles import ColesIterableDataset\n",
        "from ptls.frames.coles.split_strategy import SampleSlices\n",
        "from ptls.frames import PtlsDataModule\n",
        "from ptls.preprocessing import PandasDataPreprocessor\n",
        "from ptls.data_load.utils import collate_feature_dict\n",
        "from ptls.data_load.iterable_processing_dataset import IterableProcessingDataset\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import lightgbm as ltb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b11ff44",
      "metadata": {
        "id": "4b11ff44"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2840f9d6-d3f4-4c51-aaf9-a02e8d1fd538",
      "metadata": {
        "id": "2840f9d6-d3f4-4c51-aaf9-a02e8d1fd538"
      },
      "outputs": [],
      "source": [
        "transactions_train = pd.read_parquet(\"trx_train.parquet\")\n",
        "transactions_test = pd.read_parquet(\"trx_test.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ade92a4b-f6a3-45c2-8c42-cf61afcdbaae",
      "metadata": {
        "id": "ade92a4b-f6a3-45c2-8c42-cf61afcdbaae",
        "outputId": "a81b3868-29e6-4a03-cd02-2d9e795767db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 38min, sys: 4min 3s, total: 42min 3s\n",
            "Wall time: 41min 56s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "preprocessor = PandasDataPreprocessor(\n",
        "    col_id=\"client_id\",\n",
        "    col_event_time=\"event_time\",\n",
        "    event_time_transformation=\"dt_to_timestamp\",\n",
        "    cols_category=[\"event_type\",\n",
        "                   \"event_subtype\",\n",
        "                   \"currency\",\n",
        "                   \"src_type11\",\n",
        "                   \"src_type12\",\n",
        "                   \"dst_type11\",\n",
        "                   \"dst_type12\",\n",
        "                   \"src_type21\",\n",
        "                   \"src_type22\",\n",
        "                   \"src_type31\",\n",
        "                   \"src_type32\"],\n",
        "    cols_identity=\"amount\",\n",
        "    return_records=False,\n",
        ")\n",
        "\n",
        "processed_train = preprocessor.fit_transform(transactions_train)\n",
        "\n",
        "processed_test = preprocessor.transform(transactions_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22b7f016-2da0-4695-b663-780421e6d224",
      "metadata": {
        "id": "22b7f016-2da0-4695-b663-780421e6d224"
      },
      "outputs": [],
      "source": [
        "target_train = pd.read_parquet(\"train_target.parquet\")\n",
        "\n",
        "target_preprocessor = PandasDataPreprocessor(\n",
        "    col_id=\"client_id\",\n",
        "    col_event_time=\"mon\",\n",
        "    event_time_transformation=\"dt_to_timestamp\",\n",
        "    cols_identity=[\"target_1\", \"target_2\", \"target_3\", \"target_4\"],\n",
        "    return_records=False,\n",
        ")\n",
        "\n",
        "processed_target = target_preprocessor.fit_transform(target_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aec46f63-b964-4fd1-b9f1-d1504bf7092f",
      "metadata": {
        "id": "aec46f63-b964-4fd1-b9f1-d1504bf7092f"
      },
      "outputs": [],
      "source": [
        "test_target_b = pd.read_parquet(\"test_target_b.parquet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd06607a",
      "metadata": {
        "id": "fd06607a"
      },
      "source": [
        "**Обработка датасета:**\n",
        "\n",
        "- Транзакции, у которых размер < min_seq_len выкидываются\n",
        "- Транзакции, у которых длина > max_seq_len, обрезаются и конвертируются в torch.tensor\n",
        "- Не нужные для CoLES фичи удаляются"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a97b4ffb-490d-4591-a011-38c845430377",
      "metadata": {
        "id": "a97b4ffb-490d-4591-a011-38c845430377"
      },
      "outputs": [],
      "source": [
        "train = MemoryMapDataset(\n",
        "    data=processed_train.to_dict(\"records\"),\n",
        "    i_filters=[\n",
        "        FeatureFilter(drop_feature_names=['client_id', 'target_1', 'target_2', 'target_3', 'target_4']),\n",
        "        SeqLenFilter(min_seq_len=32),\n",
        "        ISeqLenLimit(max_seq_len=4096),\n",
        "        ToTorch()\n",
        "    ]\n",
        ")\n",
        "\n",
        "test = MemoryMapDataset(\n",
        "    data=processed_test.to_dict(\"records\"),\n",
        "    i_filters=[\n",
        "        FeatureFilter(drop_feature_names=['client_id', 'target_1', 'target_2', 'target_3', 'target_4']),\n",
        "        SeqLenFilter(min_seq_len=32),\n",
        "        ISeqLenLimit(max_seq_len=4096),\n",
        "        ToTorch()\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1a926ca",
      "metadata": {
        "id": "a1a926ca",
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_ds = ColesIterableDataset(\n",
        "    data=train,\n",
        "    splitter=SampleSlices(\n",
        "        split_count=5,\n",
        "        cnt_min=32,\n",
        "        cnt_max=180\n",
        "    )\n",
        ")\n",
        "\n",
        "valid_ds = ColesIterableDataset(\n",
        "    data=test,\n",
        "    splitter=SampleSlices(\n",
        "        split_count=5,\n",
        "        cnt_min=32,\n",
        "        cnt_max=180\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baac6b81",
      "metadata": {
        "id": "baac6b81",
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_dl = PtlsDataModule(\n",
        "    train_data=train_ds,\n",
        "    train_num_workers=16,\n",
        "    train_batch_size=256,\n",
        "    valid_data=valid_ds,\n",
        "    valid_num_workers=16,\n",
        "    valid_batch_size=256\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2da65edc",
      "metadata": {
        "id": "2da65edc"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "190206c4",
      "metadata": {
        "id": "190206c4"
      },
      "source": [
        "- numeric_values обрабатываются как BatchNorm+Linear\n",
        "- embedidngs - nn.Embedidngs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e48607f",
      "metadata": {
        "id": "3e48607f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "trx_encoder_params = dict(\n",
        "    embeddings_noise=0.003,\n",
        "    numeric_values={'amount': 'log'},\n",
        "    embeddings={\n",
        "        \"event_type\": {'in': preprocessor.get_category_dictionary_sizes()[\"event_type\"], \"out\": 24},\n",
        "        \"event_subtype\": {'in': preprocessor.get_category_dictionary_sizes()[\"event_subtype\"], \"out\": 24},\n",
        "        'src_type11': {'in': preprocessor.get_category_dictionary_sizes()[\"src_type11\"], 'out': 24},\n",
        "        'src_type12': {'in': preprocessor.get_category_dictionary_sizes()[\"src_type12\"], 'out': 24},\n",
        "        'dst_type11': {'in': preprocessor.get_category_dictionary_sizes()[\"dst_type11\"], 'out': 24},\n",
        "        'dst_type12': {'in': preprocessor.get_category_dictionary_sizes()[\"dst_type12\"], 'out': 24},\n",
        "        'src_type22': {'in': preprocessor.get_category_dictionary_sizes()[\"src_type22\"], 'out': 24},\n",
        "        'src_type31': {'in': preprocessor.get_category_dictionary_sizes()[\"src_type31\"], 'out': 24},\n",
        "        'src_type32': {'in': preprocessor.get_category_dictionary_sizes()[\"src_type32\"], 'out': 24},\n",
        "      }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c0bfdd2",
      "metadata": {
        "id": "0c0bfdd2"
      },
      "source": [
        "- **TrxEncoder** - обрабатывает каждую тразнакцию (строит для неё эмбеддиг)\n",
        "- **SeqEncoder** - обрабатывает последовательность"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd8b30c9",
      "metadata": {
        "id": "bd8b30c9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "seq_encoder = RnnSeqEncoder(\n",
        "    trx_encoder=TrxEncoder(**trx_encoder_params),\n",
        "    hidden_size=256,\n",
        "    type='gru',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ae75c20",
      "metadata": {
        "id": "7ae75c20",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model = CoLESModule(\n",
        "    seq_encoder=seq_encoder,\n",
        "    optimizer_partial=partial(torch.optim.Adam, lr=0.001),\n",
        "    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=3, gamma=0.9025)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55b59d8a",
      "metadata": {
        "id": "55b59d8a"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43b7d28e",
      "metadata": {
        "id": "43b7d28e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "trainer = pl.Trainer(\n",
        "    max_epochs=30,\n",
        "    limit_val_batches=5000,\n",
        "    gpus=[0],\n",
        "    enable_progress_bar=True,\n",
        "    gradient_clip_val=0.5,\n",
        "    logger=pl.loggers.TensorBoardLogger(\n",
        "        save_dir='./logdir',\n",
        "        name='baseline_result'\n",
        "    ),\n",
        "    callbacks=[\n",
        "        pl.callbacks.LearningRateMonitor(logging_interval='step'),\n",
        "        pl.callbacks.ModelCheckpoint(every_n_train_steps=5000, save_top_k=-1),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e78dcf91",
      "metadata": {
        "id": "e78dcf91",
        "tags": []
      },
      "outputs": [],
      "source": [
        "trainer.fit(model, train_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f12c540-871e-4b12-8d13-3aa4f344b772",
      "metadata": {
        "id": "4f12c540-871e-4b12-8d13-3aa4f344b772"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), './model.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adb01664",
      "metadata": {
        "id": "adb01664"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fc52ded",
      "metadata": {
        "id": "9fc52ded"
      },
      "source": [
        "Для каждого пользователя известно 12 таргетов, инференс происходит следующим образом:\n",
        "\n",
        "Чтобы не происходило лика нужно для каждого клиента делать срез до текущего месяца:\n",
        "\n",
        "Берутся все тразнакции за первый месяц, им соответствует 1-ый таргет из 12,\n",
        "потом берутся транзакции за первый и второй месяц пользователя и им соотвествует 2-ой таргет и так далее.\n",
        "То есть для данного пользователя, имеющего транзакции за год, мы можем получить 12 эмбеддингов, каждому из которых соответствует 1 таргет"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f50e010",
      "metadata": {
        "id": "5f50e010",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class GetSplit(IterableProcessingDataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        start_month,\n",
        "        end_month,\n",
        "        year=2022,\n",
        "        col_id='client_id',\n",
        "        col_time='event_time'\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.start_month = start_month\n",
        "        self.end_month = end_month\n",
        "        self._year = year\n",
        "        self._col_id = col_id\n",
        "        self._col_time = col_time\n",
        "\n",
        "    def __iter__(self):\n",
        "        for rec in self._src:\n",
        "            for month in range(self.start_month, self.end_month+1):\n",
        "                features = rec[0] if type(rec) is tuple else rec\n",
        "                features = features.copy()\n",
        "\n",
        "                if month == 12:\n",
        "                    month_event_time = datetime(self._year + 1, 1, 1).timestamp()\n",
        "                else:\n",
        "                    month_event_time = datetime(self._year, month + 1, 1).timestamp()\n",
        "\n",
        "                year_event_time = datetime(self._year, 1, 1).timestamp()\n",
        "\n",
        "                mask = features[self._col_time] < month_event_time\n",
        "\n",
        "                for key, tensor in features.items():\n",
        "                    if key.startswith('target'):\n",
        "                        features[key] = tensor[month - 1].tolist()\n",
        "                    elif key != self._col_id:\n",
        "                        features[key] = tensor[mask]\n",
        "\n",
        "                features[self._col_id] += '_month=' + str(month)\n",
        "\n",
        "                yield features\n",
        "\n",
        "def collate_feature_dict_with_target(batch, col_id='client_id', targets=False):\n",
        "    batch_ids = []\n",
        "    target_cols = []\n",
        "    for sample in batch:\n",
        "        batch_ids.append(sample[col_id])\n",
        "        del sample[col_id]\n",
        "\n",
        "        if targets:\n",
        "            target_cols.append([sample[f'target_{i}'] for i in range(1, 5)])\n",
        "            del sample['target_1']\n",
        "            del sample['target_2']\n",
        "            del sample['target_3']\n",
        "            del sample['target_4']\n",
        "\n",
        "    padded_batch = collate_feature_dict(batch)\n",
        "    if targets:\n",
        "        return padded_batch, batch_ids, target_cols\n",
        "    return padded_batch, batch_ids\n",
        "\n",
        "\n",
        "class InferenceModuleMultimodal(pl.LightningModule):\n",
        "    def __init__(self, model, pandas_output=True, drop_seq_features=True, model_out_name='out'):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = model\n",
        "        self.pandas_output = pandas_output\n",
        "        self.drop_seq_features = drop_seq_features\n",
        "        self.model_out_name = model_out_name\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_len = len(x)\n",
        "        if x_len == 3:\n",
        "            x, batch_ids, target_cols = x\n",
        "        else:\n",
        "            x, batch_ids = x\n",
        "\n",
        "        out = self.model(x)\n",
        "        if x_len == 3:\n",
        "            target_cols = torch.tensor(target_cols)\n",
        "            x_out = {\n",
        "                'client_id': batch_ids,\n",
        "                'target_1': target_cols[:, 0],\n",
        "                'target_2': target_cols[:, 1],\n",
        "                'target_3': target_cols[:, 2],\n",
        "                'target_4': target_cols[:, 3],\n",
        "                self.model_out_name: out\n",
        "            }\n",
        "        else:\n",
        "            x_out = {\n",
        "                'client_id': batch_ids,\n",
        "                self.model_out_name: out\n",
        "            }\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        if self.pandas_output:\n",
        "            return self.to_pandas(x_out)\n",
        "        return x_out\n",
        "\n",
        "    @staticmethod\n",
        "    def to_pandas(x):\n",
        "        expand_cols = []\n",
        "        scalar_features = {}\n",
        "\n",
        "        for k, v in x.items():\n",
        "            if type(v) is torch.Tensor:\n",
        "                v = v.cpu().numpy()\n",
        "\n",
        "            if type(v) is list or len(v.shape) == 1:\n",
        "                scalar_features[k] = v\n",
        "            elif len(v.shape) == 2:\n",
        "                expand_cols.append(k)\n",
        "            else:\n",
        "                scalar_features[k] = None\n",
        "\n",
        "        dataframes = [pd.DataFrame(scalar_features)]\n",
        "        for col in expand_cols:\n",
        "            v = x[col].cpu().numpy()\n",
        "            dataframes.append(pd.DataFrame(v, columns=[f'{col}_{i:04d}' for i in range(v.shape[1])]))\n",
        "\n",
        "        return pd.concat(dataframes, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c4a667a",
      "metadata": {
        "id": "6c4a667a",
        "outputId": "94dafa49-939f-45c1-8f5f-0eda5562e4b9",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 17min 46s, sys: 2min 11s, total: 19min 58s\n",
            "Wall time: 19min 46s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "train = MemoryMapDataset(\n",
        "    data=processed_train.merge(processed_target.drop(\"event_time\", axis=1), on=\"client_id\", how=\"inner\").to_dict(\"records\"),\n",
        "    i_filters=[\n",
        "        ISeqLenLimit(max_seq_len=4096),\n",
        "        FeatureFilter(keep_feature_names=['client_id', 'target_1', 'target_2', 'target_3', 'target_4']),\n",
        "        GetSplit(start_month=1, end_month=12),\n",
        "        ToTorch(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "test = MemoryMapDataset(\n",
        "    data=processed_test.to_dict(\"records\"),\n",
        "    i_filters=[\n",
        "        ISeqLenLimit(max_seq_len=4096),\n",
        "        FeatureFilter(keep_feature_names=['client_id', 'target_1', 'target_2', 'target_3', 'target_4']),\n",
        "        ToTorch(),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b0846b6",
      "metadata": {
        "id": "1b0846b6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "inference_train_dl = DataLoader(\n",
        "        dataset=train,\n",
        "        collate_fn=partial(collate_feature_dict_with_target, targets=True),\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        batch_size=256,\n",
        "    )\n",
        "\n",
        "inference_test_dl = DataLoader(\n",
        "        dataset=test,\n",
        "        collate_fn=collate_feature_dict_with_target,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        batch_size=256,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8e7b7bd",
      "metadata": {
        "id": "b8e7b7bd",
        "tags": []
      },
      "outputs": [],
      "source": [
        "inf_module = InferenceModuleMultimodal(\n",
        "        model=model,\n",
        "        pandas_output=True,\n",
        "        drop_seq_features=True,\n",
        "        model_out_name='emb',\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72d48ed6",
      "metadata": {
        "id": "72d48ed6",
        "outputId": "15813644-e4d8-43d2-c1c1-12b0cab08cf4",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "trainer = pl.Trainer(gpus=[0], max_epochs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45dc1160",
      "metadata": {
        "id": "45dc1160",
        "tags": []
      },
      "outputs": [],
      "source": [
        "inf_test_embeddings = pd.concat(\n",
        "        trainer.predict(inf_module, inference_test_dl)\n",
        "    )\n",
        "inf_test_embeddings.to_parquet(\"test.parquet\", index=False, engine=\"pyarrow\", compression=\"snappy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "015288af",
      "metadata": {
        "id": "015288af"
      },
      "outputs": [],
      "source": [
        "del inf_test_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00044b74",
      "metadata": {
        "id": "00044b74",
        "tags": []
      },
      "outputs": [],
      "source": [
        "inf_train_embeddings = pd.concat(\n",
        "        trainer.predict(inf_module, inference_train_dl)\n",
        "    )\n",
        "\n",
        "inf_train_embeddings.to_parquet(\"train.parquet\", index=False, engine=\"pyarrow\", compression=\"snappy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13797cfa",
      "metadata": {
        "id": "13797cfa"
      },
      "outputs": [],
      "source": [
        "del inf_train_embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e0def22",
      "metadata": {},
      "source": [
        "Файл **sample_submission** составляется из **client_id** файла **test_target_b**. Так как не у всех пользователей может быть транзакционная история, мы для простоты заполняем их фичи нулями."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e54f6eb-ebf6-49fe-87df-8d13169aa3dc",
      "metadata": {
        "id": "4e54f6eb-ebf6-49fe-87df-8d13169aa3dc"
      },
      "outputs": [],
      "source": [
        "not_only_trx = pd.DataFrame({\"client_id\": test_target_b[\"client_id\"].unique()}).merge(inf_test_embeddings, how=\"left\").fillna(0)\n",
        "not_only_trx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a411279a-a95d-4a94-943f-07d80e5ff8d9",
      "metadata": {
        "id": "a411279a-a95d-4a94-943f-07d80e5ff8d9"
      },
      "outputs": [],
      "source": [
        "not_only_trx.to_parquet(\"not_only_trx.parquet\", index=False, engine=\"pyarrow\", compression=\"snappy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcdc02c0",
      "metadata": {
        "id": "dcdc02c0"
      },
      "source": [
        "# Downstream"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e971d60f",
      "metadata": {
        "id": "e971d60f"
      },
      "source": [
        "Использование эмбеддингов для даунстрим задачи. Для всех таргетов одни и те же параметры бустинга для простоты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4da7663",
      "metadata": {
        "id": "e4da7663",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class Downstream:\n",
        "    def __init__(\n",
        "        self,\n",
        "        train_path,\n",
        "        test_path,\n",
        "        params,\n",
        "        result_path,\n",
        "        col_id='client_id',\n",
        "        targets=(\n",
        "            'target_1',\n",
        "            'target_2',\n",
        "            'target_3',\n",
        "            'target_4'\n",
        "        )\n",
        "    ):\n",
        "        self.train_path = train_path\n",
        "        self.test_path = test_path\n",
        "\n",
        "        self.col_id = col_id\n",
        "        self.all_targets = targets\n",
        "        self.params = params\n",
        "        self.result_path = result_path\n",
        "        self.drop_feat = list(self.all_targets) + [self.col_id]\n",
        "\n",
        "    def fit(self):\n",
        "\n",
        "        train_embeddings = pd.read_parquet(self.train_path)\n",
        "        X_train = train_embeddings.drop(columns=self.drop_feat)\n",
        "\n",
        "        clfs = dict()\n",
        "        for col_target in self.all_targets:\n",
        "            clf = ltb.LGBMClassifier(**self.params)\n",
        "            y_train = train_embeddings[col_target]\n",
        "            clf.fit(X_train, y_train)\n",
        "            print(f'Model fitted, target: {col_target}')\n",
        "            clfs[col_target] = clf\n",
        "\n",
        "        return clfs\n",
        "\n",
        "    def get_scores(\n",
        "        self,\n",
        "        clfs\n",
        "    ):\n",
        "        scores = pd.DataFrame([])\n",
        "\n",
        "        test_embeddings_curr = pd.read_parquet(self.test_path).drop_duplicates('client_id')\n",
        "        X_test = test_embeddings_curr.drop(columns=[self.col_id])\n",
        "        ids = test_embeddings_curr[self.col_id]\n",
        "        scores[self.col_id] = ids\n",
        "\n",
        "        for col_target in self.all_targets:\n",
        "            clf = clfs[col_target]\n",
        "            score = clf.predict_proba(X_test)[:, 1]\n",
        "            scores[col_target] = score\n",
        "\n",
        "        return scores\n",
        "\n",
        "    def run(self):\n",
        "        clfs = self.fit()\n",
        "        scores = self.get_scores(clfs)\n",
        "\n",
        "        scores.to_csv(self.result_path)\n",
        "\n",
        "        return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b656f24",
      "metadata": {
        "id": "4b656f24",
        "tags": []
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    \"n_estimators\": 500,\n",
        "      \"boosting_type\": \"gbdt\",\n",
        "      \"objective\": \"binary\",\n",
        "      \"subsample\": 0.5,\n",
        "      \"subsample_freq\": 1,\n",
        "      \"learning_rate\": 0.02,\n",
        "      \"feature_fraction\": 0.75,\n",
        "      \"max_depth\": 6,\n",
        "      \"lambda_l1\": 1,\n",
        "      \"lambda_l2\": 1,\n",
        "      \"min_data_in_leaf\": 50,\n",
        "      \"random_state\": 42,\n",
        "      \"n_jobs\": 8,\n",
        "}\n",
        "\n",
        "dw = Downstream(\n",
        "    train_path=\"train.parquet\",\n",
        "    test_path=\"not_only_trx.parquet\",\n",
        "    params=params,\n",
        "    result_path='sample_submission.csv'\n",
        ")\n",
        "\n",
        "scores = dw.run()\n",
        "scores"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ptls-experiments",
      "language": "python",
      "name": "ptls-experiments"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
